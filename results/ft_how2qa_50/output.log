ERROR:root:No token file found. Also make sure that a [prod] section with a 'token = value' assignment exists.
ERROR:root:No token file found. Also make sure that a [prod] section with a 'token = value' assignment exists.
| distributed init (rank 1): env://
| distributed init (rank 0): env://
Namespace(activitynet_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/ActivityNet-QA/clipvitl14.pth', activitynet_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/ActivityNet-QA/subtitles.pkl', activitynet_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/ActivityNet-QA/test.csv', activitynet_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/ActivityNet-QA/train.csv', activitynet_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/ActivityNet-QA/val.csv', activitynet_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/ActivityNet-QA/vocab.json', batch_size=32, batch_size_val=32, beta1=0.9, beta2=0.95, blackout=True, blackout_percent=50, clip_max_norm=0.1, combine_datasets=['how2qa'], combine_datasets_val=['how2qa'], device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, dropout=0.1, ds_factor_attn=8, ds_factor_ff=8, epochs=10, eval=True, eval_skip=1, features_dim=768, fraction_warmup_steps=0.1, freeze_last=True, freeze_lm=True, freeze_mlm=True, ft_ln=True, gpu=0, how2qa_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/How2QA/clipvitl14_split.pth', how2qa_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/How2QA/subtitles.pkl', how2qa_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/How2QA/train.csv', how2qa_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/How2QA/public_val.csv', ivqa_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/iVQA/clipvitl14.pth', ivqa_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/iVQA/subtitles.pkl', ivqa_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/iVQA/test.csv', ivqa_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/iVQA/train.csv', ivqa_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/iVQA/val.csv', ivqa_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/iVQA/vocab.json', load='models/frozenbilm_how2qa.pth', lr=0.0003, lr_drop=10, lsmdc_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/LSMDC/clipvitl14.pth', lsmdc_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/LSMDC/subtitles.pkl', lsmdc_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/LSMDC/test.csv', lsmdc_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/LSMDC/training.csv', lsmdc_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/LSMDC/val.csv', lsmdc_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/LSMDC/vocab.json', max_atokens=5, max_feats=10, max_tokens=512, mlm_prob=0.15, model_name='transformers_cache/deberta-v2-xlarge', msrvtt_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSRVTT-QA/clipvitl14.pth', msrvtt_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSRVTT-QA/subtitles.pkl', msrvtt_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSRVTT-QA/test.csv', msrvtt_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSRVTT-QA/train.csv', msrvtt_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSRVTT-QA/val.csv', msrvtt_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSRVTT-QA/vocab.json', msvd_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSVD-QA/clipvitl14.pth', msvd_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSVD-QA/subtitles.pkl', msvd_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSVD-QA/test.csv', msvd_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSVD-QA/train.csv', msvd_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSVD-QA/val.csv', msvd_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/MSVD-QA/vocab.json', n_ans=0, num_workers=3, optimizer='adam', prefix='', presave_dir='', print_freq=100, question_example='', rank=0, resume=False, reverse=False, save_dir='ml/ft_how2qa_50', schedule='', scratch=False, seed=42, shuffle=False, siq_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/SIQ2/clipvitl14.pth', siq_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/SIQ2/subtitles_trimmed.pkl', siq_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/SIQ2/test_publicx3.csv', siq_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/SIQ2/train.csv', siq_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/SIQ2/public_valx3.csv', start_epoch=0, suffix='.', test=False, tgif_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TGIF-QA/clipvitl14.pth', tgif_frameqa_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TGIF-QA/test_frameqa.csv', tgif_frameqa_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TGIF-QA/train_frameqa.csv', tgif_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TGIF-QA/vocab.json', tvqa_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TVQA/clipvitl14.pth', tvqa_subtitles_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TVQA/subtitles.pkl', tvqa_test_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TVQA/test_public.csv', tvqa_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TVQA/train.csv', tvqa_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/TVQA/val.csv', use_context=True, use_video=True, video_example='', vqa_features_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/VQA/clipvitl14.pth', vqa_train_pkl_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/VQA/train_list.pkl', vqa_val_pkl_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/VQA/val_list.csv', vqa_vocab_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/VQA/vocab.json', webvid_features_path='webvid_clipvitl14_features', webvid_train_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/WebVid/train_captions.csv', webvid_val_csv_path='/home/admin-guest/Documents/multimodal-ml/iqui/FrozenBiLM/datasets/WebVid/val_captions.csv', weight_decay=0, world_size=2)
Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at transformers_cache/deberta-v2-xlarge and are newly initialized: ['deberta.encoder.layer.3.attention.output.adapter.down.weight', 'deberta.encoder.layer.8.attention.output.adapter.up.weight', 'deberta.encoder.layer.16.attention.output.adapter.up.weight', 'deberta.encoder.layer.16.output.adapter.down.bias', 'deberta.encoder.layer.16.output.adapter.down.weight', 'deberta.encoder.layer.20.attention.output.adapter.down.bias', 'deberta.encoder.layer.1.output.adapter.up.weight', 'deberta.encoder.layer.7.output.adapter.down.weight', 'deberta.encoder.layer.2.attention.output.adapter.down.weight', 'deberta.encoder.layer.21.attention.output.adapter.up.bias', 'deberta.encoder.layer.15.attention.output.adapter.down.bias', 'deberta.encoder.layer.2.attention.output.adapter.down.bias', 'lm_predictions.lm_head.decoder.weight', 'deberta.encoder.layer.5.output.adapter.up.bias', 'deberta.encoder.layer.1.attention.output.adapter.up.weight', 'deberta.encoder.layer.23.output.adapter.down.bias', 'deberta.embeddings.linear_video.weight', 'deberta.encoder.layer.21.output.adapter.down.weight', 'deberta.encoder.layer.2.attention.output.adapter.up.weight', 'deberta.encoder.layer.6.attention.output.adapter.down.weight', 'deberta.encoder.layer.8.attention.output.adapter.up.bias', 'deberta.encoder.layer.15.output.adapter.up.bias', 'deberta.encoder.layer.4.attention.output.adapter.down.weight', 'deberta.encoder.layer.7.output.adapter.up.weight', 'deberta.encoder.layer.12.output.adapter.up.weight', 'deberta.encoder.layer.14.output.adapter.up.weight', 'deberta.encoder.layer.10.attention.output.adapter.up.bias', 'deberta.encoder.layer.1.attention.output.adapter.down.bias', 'deberta.encoder.layer.3.output.adapter.up.weight', 'deberta.encoder.layer.14.attention.output.adapter.down.bias', 'deberta.encoder.layer.21.attention.output.adapter.up.weight', 'deberta.encoder.layer.14.output.adapter.up.bias', 'deberta.encoder.layer.10.output.adapter.down.bias', 'deberta.encoder.layer.14.attention.output.adapter.up.weight', 'deberta.encoder.layer.12.attention.output.adapter.down.bias', 'deberta.encoder.layer.13.output.adapter.up.weight', 'deberta.encoder.layer.9.output.adapter.up.weight', 'deberta.encoder.layer.0.attention.output.adapter.up.weight', 'deberta.encoder.layer.19.attention.output.adapter.down.weight', 'deberta.encoder.layer.7.output.adapter.down.bias', 'deberta.encoder.layer.13.output.adapter.down.weight', 'deberta.encoder.layer.2.output.adapter.up.weight', 'deberta.encoder.layer.0.attention.output.adapter.down.bias', 'deberta.encoder.layer.17.output.adapter.up.bias', 'deberta.encoder.layer.12.attention.output.adapter.up.bias', 'deberta.encoder.layer.12.output.adapter.up.bias', 'deberta.encoder.layer.18.output.adapter.down.weight', 'deberta.encoder.layer.22.output.adapter.up.bias', 'deberta.encoder.layer.4.attention.output.adapter.down.bias', 'deberta.encoder.layer.9.attention.output.adapter.down.weight', 'deberta.encoder.layer.16.attention.output.adapter.down.weight', 'deberta.encoder.layer.0.output.adapter.up.weight', 'deberta.encoder.layer.8.output.adapter.up.weight', 'deberta.encoder.layer.18.output.adapter.up.weight', 'deberta.encoder.layer.5.output.adapter.up.weight', 'deberta.encoder.layer.3.output.adapter.up.bias', 'deberta.encoder.layer.5.output.adapter.down.bias', 'deberta.encoder.layer.3.attention.output.adapter.down.bias', 'deberta.encoder.layer.12.output.adapter.down.bias', 'deberta.encoder.layer.13.attention.output.adapter.up.weight', 'deberta.encoder.layer.18.output.adapter.up.bias', 'deberta.encoder.layer.3.output.adapter.down.bias', 'deberta.encoder.layer.7.attention.output.adapter.up.bias', 'deberta.encoder.layer.19.output.adapter.up.weight', 'deberta.encoder.layer.13.attention.output.adapter.down.weight', 'deberta.encoder.layer.7.output.adapter.up.bias', 'deberta.encoder.layer.15.output.adapter.up.weight', 'deberta.encoder.layer.18.attention.output.adapter.up.weight', 'deberta.encoder.layer.10.attention.output.adapter.down.bias', 'deberta.encoder.layer.23.output.adapter.down.weight', 'lm_predictions.lm_head.decoder.bias', 'deberta.encoder.layer.2.output.adapter.up.bias', 'deberta.encoder.layer.19.attention.output.adapter.down.bias', 'deberta.encoder.layer.22.attention.output.adapter.up.bias', 'deberta.encoder.layer.17.attention.output.adapter.up.bias', 'deberta.encoder.layer.13.attention.output.adapter.up.bias', 'deberta.embeddings.linear_video.bias', 'deberta.encoder.layer.8.output.adapter.down.bias', 'deberta.encoder.layer.0.output.adapter.up.bias', 'deberta.encoder.layer.15.attention.output.adapter.up.bias', 'deberta.encoder.layer.6.output.adapter.down.bias', 'deberta.encoder.layer.21.attention.output.adapter.down.bias', 'deberta.encoder.layer.6.attention.output.adapter.down.bias', 'deberta.encoder.layer.10.attention.output.adapter.up.weight', 'deberta.encoder.layer.5.attention.output.adapter.up.weight', 'deberta.encoder.layer.23.output.adapter.up.bias', 'deberta.encoder.layer.18.attention.output.adapter.down.bias', 'deberta.encoder.layer.19.output.adapter.down.weight', 'deberta.encoder.layer.5.attention.output.adapter.down.weight', 'answer_embeddings.weight', 'deberta.encoder.layer.17.output.adapter.down.weight', 'deberta.encoder.layer.1.attention.output.adapter.up.bias', 'deberta.encoder.layer.9.attention.output.adapter.up.bias', 'answer_bias', 'deberta.encoder.layer.1.output.adapter.down.weight', 'deberta.encoder.layer.12.attention.output.adapter.down.weight', 'deberta.encoder.layer.16.attention.output.adapter.down.bias', 'deberta.encoder.layer.20.attention.output.adapter.down.weight', 'deberta.encoder.layer.0.output.adapter.down.weight', 'deberta.encoder.layer.19.output.adapter.up.bias', 'deberta.encoder.layer.15.output.adapter.down.weight', 'deberta.encoder.layer.7.attention.output.adapter.down.weight', 'deberta.encoder.layer.13.output.adapter.down.bias', 'deberta.encoder.layer.17.attention.output.adapter.down.bias', 'deberta.encoder.layer.4.attention.output.adapter.up.weight', 'deberta.encoder.layer.18.attention.output.adapter.down.weight', 'deberta.encoder.layer.22.output.adapter.down.weight', 'deberta.encoder.layer.14.output.adapter.down.weight', 'deberta.encoder.layer.18.output.adapter.down.bias', 'deberta.encoder.layer.9.attention.output.adapter.up.weight', 'deberta.encoder.layer.3.attention.output.adapter.up.weight', 'deberta.encoder.layer.21.attention.output.adapter.down.weight', 'deberta.encoder.layer.8.attention.output.adapter.down.weight', 'deberta.encoder.layer.9.output.adapter.down.weight', 'deberta.encoder.layer.22.attention.output.adapter.down.weight', 'deberta.encoder.layer.17.output.adapter.down.bias', 'deberta.encoder.layer.9.output.adapter.up.bias', 'deberta.encoder.layer.23.output.adapter.up.weight', 'deberta.encoder.layer.14.attention.output.adapter.up.bias', 'deberta.encoder.layer.11.attention.output.adapter.down.bias', 'deberta.encoder.layer.7.attention.output.adapter.up.weight', 'deberta.encoder.layer.20.output.adapter.down.weight', 'deberta.encoder.layer.13.attention.output.adapter.down.bias', 'deberta.encoder.layer.23.attention.output.adapter.up.weight', 'deberta.encoder.layer.4.output.adapter.up.bias', 'deberta.encoder.layer.20.attention.output.adapter.up.weight', 'deberta.encoder.layer.6.output.adapter.up.bias', 'deberta.encoder.layer.14.attention.output.adapter.down.weight', 'deberta.encoder.layer.23.attention.output.adapter.up.bias', 'deberta.encoder.layer.11.output.adapter.up.weight', 'deberta.encoder.layer.20.output.adapter.down.bias', 'deberta.encoder.layer.20.attention.output.adapter.up.bias', 'deberta.encoder.layer.11.output.adapter.down.weight', 'deberta.encoder.layer.10.attention.output.adapter.down.weight', 'deberta.encoder.layer.21.output.adapter.up.weight', 'deberta.encoder.layer.16.output.adapter.up.weight', 'deberta.encoder.layer.8.attention.output.adapter.down.bias', 'deberta.encoder.layer.2.output.adapter.down.weight', 'deberta.encoder.layer.0.output.adapter.down.bias', 'deberta.encoder.layer.2.output.adapter.down.bias', 'deberta.encoder.layer.11.attention.output.adapter.up.weight', 'deberta.encoder.layer.19.attention.output.adapter.up.weight', 'deberta.encoder.layer.12.attention.output.adapter.up.weight', 'deberta.encoder.layer.19.output.adapter.down.bias', 'deberta.encoder.layer.10.output.adapter.up.weight', 'deberta.encoder.layer.19.attention.output.adapter.up.bias', 'deberta.encoder.layer.4.output.adapter.down.weight', 'deberta.encoder.layer.7.attention.output.adapter.down.bias', 'deberta.encoder.layer.2.attention.output.adapter.up.bias', 'deberta.encoder.layer.5.output.adapter.down.weight', 'deberta.encoder.layer.4.output.adapter.down.bias', 'deberta.encoder.layer.5.attention.output.adapter.down.bias', 'deberta.encoder.layer.11.output.adapter.down.bias', 'deberta.encoder.layer.18.attention.output.adapter.up.bias', 'deberta.encoder.layer.1.attention.output.adapter.down.weight', 'deberta.encoder.layer.16.attention.output.adapter.up.bias', 'deberta.encoder.layer.6.output.adapter.up.weight', 'deberta.encoder.layer.11.attention.output.adapter.down.weight', 'deberta.encoder.layer.14.output.adapter.down.bias', 'deberta.encoder.layer.8.output.adapter.down.weight', 'deberta.encoder.layer.3.output.adapter.down.weight', 'deberta.encoder.layer.10.output.adapter.down.weight', 'deberta.encoder.layer.21.output.adapter.down.bias', 'deberta.encoder.layer.9.output.adapter.down.bias', 'deberta.encoder.layer.9.attention.output.adapter.down.bias', 'deberta.encoder.layer.11.attention.output.adapter.up.bias', 'deberta.encoder.layer.11.output.adapter.up.bias', 'deberta.encoder.layer.15.attention.output.adapter.down.weight', 'deberta.encoder.layer.4.attention.output.adapter.up.bias', 'deberta.encoder.layer.0.attention.output.adapter.down.weight', 'deberta.encoder.layer.23.attention.output.adapter.down.bias', 'deberta.encoder.layer.5.attention.output.adapter.up.bias', 'deberta.encoder.layer.20.output.adapter.up.weight', 'deberta.encoder.layer.6.output.adapter.down.weight', 'deberta.encoder.layer.0.attention.output.adapter.up.bias', 'deberta.encoder.layer.4.output.adapter.up.weight', 'deberta.encoder.layer.1.output.adapter.up.bias', 'deberta.encoder.layer.17.attention.output.adapter.down.weight', 'deberta.encoder.layer.17.attention.output.adapter.up.weight', 'deberta.encoder.layer.22.output.adapter.down.bias', 'deberta.encoder.layer.22.attention.output.adapter.up.weight', 'deberta.encoder.layer.6.attention.output.adapter.up.bias', 'deberta.encoder.layer.12.output.adapter.down.weight', 'deberta.encoder.layer.13.output.adapter.up.bias', 'deberta.encoder.layer.6.attention.output.adapter.up.weight', 'deberta.encoder.layer.1.output.adapter.down.bias', 'deberta.encoder.layer.17.output.adapter.up.weight', 'deberta.encoder.layer.22.attention.output.adapter.down.bias', 'deberta.encoder.layer.20.output.adapter.up.bias', 'deberta.encoder.layer.21.output.adapter.up.bias', 'deberta.encoder.layer.3.attention.output.adapter.up.bias', 'deberta.encoder.layer.22.output.adapter.up.weight', 'deberta.encoder.layer.23.attention.output.adapter.down.weight', 'deberta.encoder.layer.15.output.adapter.down.bias', 'deberta.encoder.layer.15.attention.output.adapter.up.weight', 'deberta.encoder.layer.16.output.adapter.up.bias', 'deberta.encoder.layer.10.output.adapter.up.bias', 'deberta.encoder.layer.8.output.adapter.up.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at transformers_cache/deberta-v2-xlarge and are newly initialized: ['deberta.encoder.layer.21.output.adapter.down.weight', 'deberta.encoder.layer.16.output.adapter.up.bias', 'deberta.encoder.layer.10.output.adapter.up.bias', 'deberta.encoder.layer.18.attention.output.adapter.up.weight', 'deberta.encoder.layer.17.attention.output.adapter.down.weight', 'deberta.encoder.layer.6.attention.output.adapter.down.bias', 'deberta.encoder.layer.5.output.adapter.up.bias', 'deberta.encoder.layer.21.output.adapter.up.weight', 'deberta.encoder.layer.19.output.adapter.down.bias', 'deberta.encoder.layer.23.output.adapter.down.weight', 'deberta.encoder.layer.6.attention.output.adapter.up.bias', 'deberta.encoder.layer.15.attention.output.adapter.down.bias', 'deberta.encoder.layer.4.attention.output.adapter.down.bias', 'deberta.encoder.layer.23.attention.output.adapter.down.bias', 'deberta.encoder.layer.0.attention.output.adapter.up.bias', 'deberta.encoder.layer.23.output.adapter.down.bias', 'deberta.encoder.layer.23.attention.output.adapter.down.weight', 'deberta.encoder.layer.1.output.adapter.up.weight', 'deberta.encoder.layer.12.output.adapter.up.weight', 'deberta.encoder.layer.9.output.adapter.down.weight', 'deberta.encoder.layer.19.attention.output.adapter.up.weight', 'deberta.encoder.layer.3.output.adapter.down.bias', 'deberta.encoder.layer.20.attention.output.adapter.down.bias', 'deberta.encoder.layer.8.output.adapter.up.bias', 'deberta.encoder.layer.18.output.adapter.up.weight', 'deberta.encoder.layer.19.attention.output.adapter.up.bias', 'deberta.encoder.layer.5.output.adapter.up.weight', 'deberta.encoder.layer.12.output.adapter.down.weight', 'deberta.encoder.layer.22.attention.output.adapter.down.weight', 'deberta.encoder.layer.8.attention.output.adapter.up.bias', 'deberta.encoder.layer.1.attention.output.adapter.down.bias', 'deberta.encoder.layer.9.output.adapter.up.weight', 'deberta.encoder.layer.18.attention.output.adapter.up.bias', 'deberta.encoder.layer.19.attention.output.adapter.down.bias', 'deberta.encoder.layer.2.output.adapter.up.weight', 'deberta.encoder.layer.18.output.adapter.down.weight', 'deberta.encoder.layer.13.output.adapter.down.bias', 'deberta.encoder.layer.17.attention.output.adapter.down.bias', 'deberta.encoder.layer.6.output.adapter.down.weight', 'deberta.encoder.layer.1.attention.output.adapter.down.weight', 'deberta.encoder.layer.22.attention.output.adapter.down.bias', 'deberta.encoder.layer.17.output.adapter.down.weight', 'deberta.encoder.layer.3.attention.output.adapter.up.weight', 'deberta.encoder.layer.1.output.adapter.down.weight', 'deberta.encoder.layer.16.attention.output.adapter.up.bias', 'deberta.encoder.layer.22.attention.output.adapter.up.bias', 'deberta.encoder.layer.8.attention.output.adapter.down.weight', 'deberta.encoder.layer.17.output.adapter.down.bias', 'deberta.encoder.layer.11.output.adapter.up.weight', 'deberta.encoder.layer.3.attention.output.adapter.up.bias', 'deberta.encoder.layer.5.output.adapter.down.bias', 'deberta.encoder.layer.23.attention.output.adapter.up.bias', 'deberta.encoder.layer.7.attention.output.adapter.down.weight', 'deberta.encoder.layer.20.output.adapter.down.weight', 'deberta.encoder.layer.5.attention.output.adapter.up.weight', 'deberta.encoder.layer.16.attention.output.adapter.down.weight', 'deberta.encoder.layer.15.attention.output.adapter.down.weight', 'deberta.encoder.layer.19.output.adapter.up.bias', 'deberta.encoder.layer.3.output.adapter.up.bias', 'deberta.encoder.layer.22.attention.output.adapter.up.weight', 'deberta.encoder.layer.10.output.adapter.up.weight', 'deberta.encoder.layer.8.attention.output.adapter.down.bias', 'deberta.encoder.layer.14.output.adapter.down.weight', 'deberta.encoder.layer.3.output.adapter.down.weight', 'deberta.encoder.layer.18.output.adapter.down.bias', 'deberta.encoder.layer.8.attention.output.adapter.up.weight', 'deberta.encoder.layer.21.output.adapter.down.bias', 'deberta.encoder.layer.13.attention.output.adapter.up.weight', 'deberta.encoder.layer.5.attention.output.adapter.up.bias', 'deberta.encoder.layer.6.attention.output.adapter.up.weight', 'deberta.encoder.layer.16.attention.output.adapter.down.bias', 'deberta.encoder.layer.4.output.adapter.down.bias', 'deberta.encoder.layer.17.output.adapter.up.weight', 'deberta.encoder.layer.3.output.adapter.up.weight', 'deberta.encoder.layer.16.output.adapter.up.weight', 'deberta.encoder.layer.15.attention.output.adapter.up.bias', 'deberta.encoder.layer.15.output.adapter.down.weight', 'deberta.encoder.layer.4.attention.output.adapter.down.weight', 'deberta.encoder.layer.12.attention.output.adapter.down.weight', 'deberta.encoder.layer.2.output.adapter.down.bias', 'deberta.encoder.layer.20.output.adapter.down.bias', 'deberta.encoder.layer.14.attention.output.adapter.up.weight', 'deberta.encoder.layer.15.output.adapter.down.bias', 'deberta.encoder.layer.7.output.adapter.up.bias', 'deberta.encoder.layer.8.output.adapter.down.weight', 'lm_predictions.lm_head.decoder.bias', 'deberta.encoder.layer.21.attention.output.adapter.down.bias', 'deberta.encoder.layer.15.attention.output.adapter.up.weight', 'deberta.encoder.layer.14.attention.output.adapter.down.weight', 'deberta.encoder.layer.9.attention.output.adapter.down.weight', 'deberta.encoder.layer.10.attention.output.adapter.down.bias', 'deberta.encoder.layer.9.attention.output.adapter.up.bias', 'deberta.encoder.layer.5.attention.output.adapter.down.weight', 'deberta.encoder.layer.9.output.adapter.up.bias', 'deberta.encoder.layer.0.attention.output.adapter.down.bias', 'deberta.encoder.layer.5.attention.output.adapter.down.bias', 'deberta.encoder.layer.11.attention.output.adapter.down.bias', 'deberta.encoder.layer.2.attention.output.adapter.down.weight', 'deberta.encoder.layer.14.attention.output.adapter.up.bias', 'deberta.encoder.layer.12.attention.output.adapter.up.bias', 'deberta.encoder.layer.22.output.adapter.up.weight', 'deberta.encoder.layer.3.attention.output.adapter.down.weight', 'deberta.embeddings.linear_video.weight', 'deberta.encoder.layer.15.output.adapter.up.weight', 'deberta.encoder.layer.23.output.adapter.up.weight', 'deberta.encoder.layer.2.attention.output.adapter.up.bias', 'deberta.encoder.layer.13.output.adapter.down.weight', 'deberta.encoder.layer.1.output.adapter.up.bias', 'lm_predictions.lm_head.decoder.weight', 'deberta.encoder.layer.17.attention.output.adapter.up.weight', 'deberta.encoder.layer.7.attention.output.adapter.down.bias', 'deberta.encoder.layer.15.output.adapter.up.bias', 'deberta.encoder.layer.21.attention.output.adapter.down.weight', 'answer_embeddings.weight', 'deberta.encoder.layer.16.output.adapter.down.weight', 'deberta.encoder.layer.5.output.adapter.down.weight', 'answer_bias', 'deberta.encoder.layer.0.output.adapter.down.weight', 'deberta.encoder.layer.2.output.adapter.down.weight', 'deberta.encoder.layer.6.output.adapter.up.bias', 'deberta.encoder.layer.9.attention.output.adapter.up.weight', 'deberta.encoder.layer.4.output.adapter.up.bias', 'deberta.encoder.layer.20.attention.output.adapter.up.weight', 'deberta.encoder.layer.21.output.adapter.up.bias', 'deberta.encoder.layer.20.output.adapter.up.bias', 'deberta.encoder.layer.4.attention.output.adapter.up.weight', 'deberta.encoder.layer.1.output.adapter.down.bias', 'deberta.encoder.layer.20.attention.output.adapter.down.weight', 'deberta.encoder.layer.7.attention.output.adapter.up.weight', 'deberta.encoder.layer.7.output.adapter.up.weight', 'deberta.encoder.layer.18.output.adapter.up.bias', 'deberta.encoder.layer.0.attention.output.adapter.down.weight', 'deberta.encoder.layer.1.attention.output.adapter.up.bias', 'deberta.encoder.layer.7.output.adapter.down.weight', 'deberta.encoder.layer.4.output.adapter.down.weight', 'deberta.encoder.layer.11.output.adapter.down.bias', 'deberta.encoder.layer.13.attention.output.adapter.down.bias', 'deberta.encoder.layer.0.output.adapter.up.weight', 'deberta.encoder.layer.14.output.adapter.down.bias', 'deberta.encoder.layer.9.output.adapter.down.bias', 'deberta.encoder.layer.23.output.adapter.up.bias', 'deberta.encoder.layer.12.output.adapter.up.bias', 'deberta.encoder.layer.11.attention.output.adapter.up.bias', 'deberta.encoder.layer.9.attention.output.adapter.down.bias', 'deberta.encoder.layer.2.attention.output.adapter.up.weight', 'deberta.encoder.layer.4.output.adapter.up.weight', 'deberta.encoder.layer.11.attention.output.adapter.down.weight', 'deberta.encoder.layer.22.output.adapter.up.bias', 'deberta.encoder.layer.11.attention.output.adapter.up.weight', 'deberta.encoder.layer.12.attention.output.adapter.up.weight', 'deberta.encoder.layer.11.output.adapter.up.bias', 'deberta.encoder.layer.10.output.adapter.down.bias', 'deberta.encoder.layer.0.output.adapter.up.bias', 'deberta.encoder.layer.7.attention.output.adapter.up.bias', 'deberta.encoder.layer.16.attention.output.adapter.up.weight', 'deberta.encoder.layer.12.output.adapter.down.bias', 'deberta.embeddings.linear_video.bias', 'deberta.encoder.layer.10.attention.output.adapter.up.weight', 'deberta.encoder.layer.22.output.adapter.down.weight', 'deberta.encoder.layer.20.attention.output.adapter.up.bias', 'deberta.encoder.layer.14.attention.output.adapter.down.bias', 'deberta.encoder.layer.0.output.adapter.down.bias', 'deberta.encoder.layer.12.attention.output.adapter.down.bias', 'deberta.encoder.layer.19.output.adapter.down.weight', 'deberta.encoder.layer.6.attention.output.adapter.down.weight', 'deberta.encoder.layer.10.attention.output.adapter.up.bias', 'deberta.encoder.layer.7.output.adapter.down.bias', 'deberta.encoder.layer.18.attention.output.adapter.down.bias', 'deberta.encoder.layer.4.attention.output.adapter.up.bias', 'deberta.encoder.layer.10.attention.output.adapter.down.weight', 'deberta.encoder.layer.6.output.adapter.down.bias', 'deberta.encoder.layer.18.attention.output.adapter.down.weight', 'deberta.encoder.layer.21.attention.output.adapter.up.bias', 'deberta.encoder.layer.2.attention.output.adapter.down.bias', 'deberta.encoder.layer.17.attention.output.adapter.up.bias', 'deberta.encoder.layer.23.attention.output.adapter.up.weight', 'deberta.encoder.layer.1.attention.output.adapter.up.weight', 'deberta.encoder.layer.6.output.adapter.up.weight', 'deberta.encoder.layer.13.output.adapter.up.bias', 'deberta.encoder.layer.10.output.adapter.down.weight', 'deberta.encoder.layer.16.output.adapter.down.bias', 'deberta.encoder.layer.21.attention.output.adapter.up.weight', 'deberta.encoder.layer.8.output.adapter.down.bias', 'deberta.encoder.layer.13.output.adapter.up.weight', 'deberta.encoder.layer.2.output.adapter.up.bias', 'deberta.encoder.layer.13.attention.output.adapter.up.bias', 'deberta.encoder.layer.14.output.adapter.up.weight', 'deberta.encoder.layer.20.output.adapter.up.weight', 'deberta.encoder.layer.0.attention.output.adapter.up.weight', 'deberta.encoder.layer.19.attention.output.adapter.down.weight', 'deberta.encoder.layer.3.attention.output.adapter.down.bias', 'deberta.encoder.layer.8.output.adapter.up.weight', 'deberta.encoder.layer.14.output.adapter.up.bias', 'deberta.encoder.layer.19.output.adapter.up.weight', 'deberta.encoder.layer.11.output.adapter.down.weight', 'deberta.encoder.layer.22.output.adapter.down.bias', 'deberta.encoder.layer.17.output.adapter.up.bias', 'deberta.encoder.layer.13.attention.output.adapter.down.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
number of params: 29735424
loading from models/frozenbilm_how2qa.pth
val:  [ 0/45]  eta: 0:03:30  acc: 0.8281 (0.8281)  time: 4.6820  data: 0.4224  max mem: 9047
val:  [44/45]  eta: 0:00:03  acc: 0.8906 (0.8522)  time: 3.5986  data: 0.0024  max mem: 10718
val: Total time: 0:02:42 (3.6184 s / it)
how2qa
val acc:  85.16%
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
